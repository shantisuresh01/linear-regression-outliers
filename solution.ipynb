{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario\n",
    "\n",
    "A hospital is measuring the heights of admitted patients.\n",
    "\n",
    "The data of such measurements is located in data.csv.  There are 3 columns.  The first column is the date.  Second column contains the number of patients admitted on such date.  The third column is the average height of the admitted patients for that day.\n",
    "\n",
    "# Task\n",
    "\n",
    "1) How can one retrospectively identify outliers?  In other words, having seen the data for the past ten months, can we identify erroneous values?  Please create code to test such.\n",
    "\n",
    "#### Answer: Yes\n",
    "\n",
    "2) How can we proactively identify outliers?  For example, pretend today is 2020-02-01, and you have observed data for a month.  How can you check whether the values computed on 2020-02-01 are erroneous?  Please write code that can work in a proactive manner.\n",
    "\n",
    "#### Answer: Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer Explained:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Background:**<br>\n",
    "The given dataset is a time-series dfataset with two main features: <br>\n",
    "1. \"average_height\"\n",
    "2. \"num_admissions\"\n",
    "<br> The \"average_height\" feature was ruled out of the prediction for outliers for the following reason:\n",
    "Although a patient's individual height is from a normal distribution, an \"average_height\" was not correlated in any way to the number of admissions of the patients or to the day on which they were admitted.  Just for information, I studied the SD of the average_heights and it was also a narrow distribution: 0.9.\n",
    "\n",
    "We know that the \"num_admissions\" was drawn from a linear distribution of slope, \"3\" and so is correlated linearly to the day of the admission calculated from the start of the year.  That is to say, the patients admitted are inclreasing linearly as the year progresses.\n",
    "\n",
    "**Methodology used:** <br>\n",
    "Step 1: Calculate the \"delta\" number of days from the first entry data <br>\n",
    "Step 2: Harvest X as the delta days, and y as the num_admissions <br>\n",
    "Step 3: Fit a linear regression model through the given data (X and y) <br>\n",
    "Step 4: Clean outliers enough to get as close a match to slope, '3' - done by calculating the squared errors and eliminating the top 7% of the data <br>\n",
    "Step 5: Visualize the results for information <br>\n",
    "Step 6: Predict outliers: any point predicted one RMSD above or below the fitted line <br>\n",
    "    Step 6a. Calcute the SD of the residuals <br>\n",
    "    Step 6b. Check if the given date and \"num_admissions\" reading: <br>\n",
    "         **is an outiler**  - predicted value of instance falls outside 1 RMSD of the line <br>\n",
    "         **not an outlier** - predicted value of instance falls within 1 RMSD of the line\n",
    "  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import (MONTHLY, DateFormatter,\n",
    "                              rrulewrapper, RRuleLocator)\n",
    "import seaborn as sns\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"quality_data.csv\", parse_dates = [\"date\"])\n",
    "# Sort data\n",
    "data.sort_values(\"date\", inplace=True)# pos = index position of the 'date' column\n",
    "#### Use timedelta to calculate time from start of file\n",
    "pos = data.columns.get_loc('date')\n",
    "data['delta'] = (data.iloc[1:, pos] - data.iat[0,pos]) \n",
    "data.loc[0,'delta'] = pd.Timedelta(days = 0)\n",
    "# Convert 'delta' to integer # days\n",
    "data['delta'] = data['delta'] / np.timedelta64(1, 'D')\n",
    "data['delta'] = data['delta'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# rule = rrulewrapper(MONTHLY)\n",
    "# loc = RRuleLocator(rule)\n",
    "# formatter = DateFormatter('%Y-%m-%d')\n",
    "# ax.xaxis.set_major_locator(loc)\n",
    "# ax.xaxis.set_major_formatter(formatter)\n",
    "# ax.tick_params(axis='x', labelrotation=45)\n",
    "# plt.plot(data['date'], data['num_admissions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study \"num_admissions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### outliers for num_admissions using scikit learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_outliers(predictions, delta, num_admissions):\n",
    "    \"\"\"\n",
    "        clean away the 7% of points that have the largest\n",
    "        residual errors (different between the prediction\n",
    "        and the actual net worth)\n",
    "\n",
    "        return a two tuples named outliers and cleaned_data where: \n",
    "        outliers includes the top 7% of predictions with largest square-errors, and\n",
    "        cleaned_data includes tuples of the form (delta,num_admissions,errors)\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculate the residual error, descend sort, and harvest 93% of the data\n",
    "    # for the best fit to achieving a slope closest to '3'\n",
    "    \n",
    "    errors = (num_admissions-predictions)**2\n",
    "    cleaned_data = zip(delta,num_admissions,errors)\n",
    "    cleaned_data = sorted(cleaned_data,key=lambda x:x[2], reverse=True)\n",
    "    limit = int(len(num_admissions)*0.07)\n",
    "    outliers = cleaned_data[:limit]\n",
    "    return outliers, cleaned_data[limit:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cedf2965b4f64ab5af0f6eb82c63a953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Outliers MAE: 73.197\n",
      "With Outliers  MSE:8374.497\n",
      "With Outliers linear model coeff : [2.90930478]\n",
      "With Outliers linear model intercept: 15.034200743494239\n",
      "With Outliers R-squared score (training): 0.859\n",
      "\n",
      "# Outliers: 18\n",
      "\n",
      "[(160, 731, 62738.745012220745), (170, 760, 62692.14100989372), (150, 207, 59745.98448490394), (242, 480, 57162.094754720456), (199, 827, 54295.593442151076), (9, 262, 48744.71636703137), (79, 29, 46599.545246667636), (134, 618, 45419.690731194976), (115, 143, 42685.31616964764), (54, 376, 41560.26192034695), (86, 62, 41304.22605238111), (151, 255, 39736.12546946159), (175, 339, 34285.16501887485), (241, 898, 33059.72985767152), (226, 497, 30813.266594397737), (46, 322, 29976.69069156439), (184, 381, 28678.162466400885), (51, 331, 28086.828959558083)]\n",
      "\n",
      "Without Outliers MAE: 63.515\n",
      "Without Outliers MSE: 5827.038\n",
      "Without Outliers linear model coeff : [[2.95008539]]\n",
      "Without Outliers linear model intercept: [9.3579011]\n",
      "Without Outliers R-squared score: 0.901\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "lreg = LinearRegression()\n",
    "plt.close(\"all\")\n",
    "# split into input and output elements\n",
    "# Trying feature X as # days as stored in 'delta' column\n",
    "# Trying target, y, as num_admissions\n",
    "delta_pos = data.columns.get_loc(\"delta\")\n",
    "adm_pos = data.columns.get_loc(\"num_admissions\")\n",
    "X, y = data.iloc[:,delta_pos].values, data.iloc[:, adm_pos].values\n",
    "\n",
    "lreg.fit(X.reshape(-1,1),y)\n",
    "predictions = lreg.predict(X.reshape(-1,1))\n",
    "plt.figure()\n",
    "# plot the predicted line\n",
    "try:\n",
    "    plt.plot(X, predictions, color=\"blue\")\n",
    "except Exception as e:\n",
    "    pass\n",
    "# Scatter plot of original num_admission values\n",
    "plt.scatter(X, y)\n",
    "plt.show()\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y, predictions)\n",
    "print(f\"With Outliers MAE: {mae:.3f}\")\n",
    "mse = mean_squared_error(y, predictions)\n",
    "print(f'With Outliers  MSE:{mse:.3f}')\n",
    "print(f\"With Outliers linear model coeff : {lreg.coef_}\")\n",
    "print(f\"With Outliers linear model intercept: {lreg.intercept_}\")\n",
    "print('With Outliers R-squared score (training): {:.3f}'\n",
    "     .format(lreg.score(X.reshape(-1,1), y)))\n",
    "\n",
    "# # Find outliers #\n",
    "# ### identify and remove the most outlier-y points\n",
    "cleaned_data = []\n",
    "(outliers, cleaned_data) = clean_outliers( predictions, X, y )\n",
    "### Check regression with the new cleaned data\n",
    "if len(cleaned_data) > 0:\n",
    "    delta, num_admissions, errors = zip(*cleaned_data)\n",
    "    delta = np.reshape( np.array(delta), (len(delta), 1))\n",
    "    num_admissions = np.reshape( np.array(num_admissions), (len(num_admissions), 1))\n",
    "\n",
    "    ## refit the cleaned data!\n",
    "    lreg.fit(delta.reshape(-1,1), num_admissions.reshape(-1,1))\n",
    "    clean_pred = lreg.predict(delta)\n",
    "    plt.plot(delta, clean_pred, color=\"orange\")\n",
    "    plt.scatter(delta, num_admissions, color=\"orange\")\n",
    "    #plt.scatter(delta, num_admissions)\n",
    "    plt.xlabel(\"Delta Days\")\n",
    "    plt.ylabel(\"# Admissions\")\n",
    "    plt.show()\n",
    "    #print(f\"\\n# Outliers: {len(X) - len(cleaned_data)}\\n\")\n",
    "    print(f\"\\n# Outliers: {len(list(outliers))}\\n\")\n",
    "    print(f\"{outliers}\\n\")\n",
    "    # evaluate predictions\n",
    "    mae = mean_absolute_error(num_admissions, clean_pred)\n",
    "    print(f\"Without Outliers MAE: {mae:.3f}\")\n",
    "    mse = mean_squared_error(num_admissions, clean_pred)\n",
    "    print(f'Without Outliers MSE: {mse:.3f}')\n",
    "    print(f\"Without Outliers linear model coeff : {lreg.coef_}\")\n",
    "    print(f\"Without Outliers linear model intercept: {lreg.intercept_}\")\n",
    "    print(f'Without Outliers R-squared score: {lreg.score(delta, num_admissions):.3f}')\n",
    "else:\n",
    "    print(\"no outliers, no refitting to be done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSD ot SD of residuals\n",
    "import math\n",
    "# use the fitted lreg model from above\n",
    "deltas = list(zip(*outliers))[0]\n",
    "res_sq = list(zip(*cleaned_data))[2]\n",
    "clean_df = data[~data['delta'].isin(list(deltas))]\n",
    "outliers = data[data['delta'].isin(list(deltas))]\n",
    "sd_res = math.sqrt(sum(res_sq)/(len(clean_df) - 2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proactive_outlier_test(x, y, w, b, sd_res):\n",
    "    yhat = w  * x + b\n",
    "    res = abs(y - yhat)\n",
    "    if res > sd_res:\n",
    "        print(\"Outlier\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Not an outlier\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'new_num_admissions' are the patients admitted for the given day, 'new_date'\n",
    "new_date = pd.Timestamp(2020, 11, 8)\n",
    "new_delta = (new_date - pd.Timestamp(2020, 1, 1)) / np.timedelta64(1, 'D')\n",
    "new_num_admissions = 300\n",
    "w = lreg.coef_\n",
    "b = lreg.intercept_\n",
    "proactive_outlier_test(x =  new_delta, y = new_num_admissions, w = w, b = b, sd_res = sd_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not an outlier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'new_num_admissions' are the patients admitted for the given day, 'new_date'\n",
    "new_date = pd.Timestamp(2020, 2, 1)\n",
    "new_delta = (new_date - pd.Timestamp(2020, 1, 1)) / np.timedelta64(1, 'D')\n",
    "new_num_admissions = 53\n",
    "w = lreg.coef_\n",
    "b = lreg.intercept_\n",
    "proactive_outlier_test(x =  new_delta, y = new_num_admissions, w = w, b = b, sd_res = sd_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'new_num_admissions' are the patients admitted for the given day, 'new_date'\n",
    "new_date = pd.Timestamp(2020, 2, 21)\n",
    "new_delta = (new_date - pd.Timestamp(2020, 1, 1)) / np.timedelta64(1, 'D')\n",
    "new_num_admissions = 331\n",
    "w = lreg.coef_\n",
    "b = lreg.intercept_\n",
    "proactive_outlier_test(x =  new_delta, y = new_num_admissions, w = w, b = b, sd_res = sd_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
